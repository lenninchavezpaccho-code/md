"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
MÃ“DULO FASE 3.3: VALIDACIÃ“N DE SUPUESTOS POST-ESTIMACIÃ“N
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Objetivos:
1. Test de Normalidad de Residuos (Jarque-Bera + Q-Q plots)
2. Test de AutocorrelaciÃ³n (Wooldridge para panel)
3. Test de Heterocedasticidad (Breusch-Pagan)
4. AnÃ¡lisis de Multicolinealidad (VIF)

Nota: En datos financieros, es ESPERADO que normalidad falle.
      Los errores robustos (cov_type='robust') corrigen estos problemas.
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

# Importar configuraciÃ³n y modelos previos
try:
    from modulo_0_config import CONFIG, OUTPUT_DIR
    from modulo_fase32_estimacion import resultados_modelos
    print("âœ… ConfiguraciÃ³n y modelos importados")
except ImportError:
    print("âš ï¸  Ejecuta primero: modulo_0_config.py y modulo_fase32_estimacion.py")
    raise

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.stats import jarque_bera, probplot
from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey
from statsmodels.stats.outliers_influence import variance_inflation_factor
import warnings
warnings.filterwarnings('ignore')

# ==========================================
# FUNCIÃ“N: TEST DE NORMALIDAD
# ==========================================

def test_normalidad_residuos(modelo, nombre_panel="Panel", guardar=True):
    """
    Ejecuta test de Jarque-Bera y genera Q-Q plot para residuos.
    
    En datos financieros, se ESPERA rechazar normalidad (colas pesadas).
    Esto NO invalida el anÃ¡lisis si usamos errores robustos.
    
    Parameters:
        modelo (dict): Diccionario con resultados del modelo (debe tener 'residuos')
        nombre_panel (str): Nombre del panel para reportes
        guardar (bool): Si guardar grÃ¡ficos y resultados
    
    Returns:
        dict: Resultados del test
    """
    print(f"\n{'='*70}")
    print(f"TEST DE NORMALIDAD - {nombre_panel}")
    print(f"{'='*70}")
    print("Test de Jarque-Bera para residuos")
    
    residuos = modelo['residuos'].values
    
    # Test de Jarque-Bera
    jb_stat, jb_pval = jarque_bera(residuos)
    
    print(f"\nğŸ“Š Resultados:")
    print(f"   â€¢ EstadÃ­stico JB: {jb_stat:.4f}")
    print(f"   â€¢ p-valor: {jb_pval:.4f}")
    
    # InterpretaciÃ³n
    print(f"\nğŸ’¡ INTERPRETACIÃ“N:")
    if jb_pval < 0.05:
        print(f"   âŒ Se rechaza H0: Los residuos NO son normales (p={jb_pval:.4f})")
        print(f"   âœ… ESTO ES ESPERADO en datos financieros (colas pesadas)")
        print(f"   âœ… Mitigado con errores estÃ¡ndar robustos (cov_type='robust')")
    else:
        print(f"   âœ… NO se rechaza H0: Los residuos son normales (p={jb_pval:.4f})")
        print(f"   âš ï¸  Resultado inesperado - verificar datos")
    
    # EstadÃ­sticos descriptivos de residuos
    print(f"\nğŸ“ˆ EstadÃ­sticos descriptivos de residuos:")
    print(f"   â€¢ Media: {residuos.mean():.6f} (debe â‰ˆ 0)")
    print(f"   â€¢ Desv. Est.: {residuos.std():.4f}")
    print(f"   â€¢ AsimetrÃ­a: {stats.skew(residuos):.4f}")
    print(f"   â€¢ Curtosis: {stats.kurtosis(residuos):.4f}")
    print(f"   â€¢ Min: {residuos.min():.4f}")
    print(f"   â€¢ Max: {residuos.max():.4f}")
    
    # Crear Q-Q plot
    if guardar:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))
        
        # Q-Q Plot
        probplot(residuos, dist="norm", plot=ax1)
        ax1.set_title(f"Q-Q Plot: Residuos vs Normal TeÃ³rica\n{nombre_panel}", 
                      fontsize=12, fontweight='bold')
        ax1.set_xlabel("Cuantiles TeÃ³ricos (Normal)", fontsize=10)
        ax1.set_ylabel("Cuantiles Muestrales (Residuos)", fontsize=10)
        ax1.grid(True, alpha=0.3)
        
        # Histograma con curva normal superpuesta
        ax2.hist(residuos, bins=30, density=True, alpha=0.7, color='steelblue', 
                 edgecolor='black', label='Residuos')
        
        # Curva normal teÃ³rica
        mu, sigma = residuos.mean(), residuos.std()
        x = np.linspace(residuos.min(), residuos.max(), 100)
        ax2.plot(x, stats.norm.pdf(x, mu, sigma), 'r-', linewidth=2, 
                 label='Normal TeÃ³rica')
        
        ax2.set_title(f"DistribuciÃ³n de Residuos\n{nombre_panel}", 
                      fontsize=12, fontweight='bold')
        ax2.set_xlabel("Residuos", fontsize=10)
        ax2.set_ylabel("Densidad", fontsize=10)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        nombre_archivo = nombre_panel.lower().replace(' ', '_').replace(':', '')
        plt.savefig(f"{OUTPUT_DIR}/diagnosticos/normalidad_{nombre_archivo}.png", 
                    dpi=300, bbox_inches='tight')
        print(f"\nğŸ’¾ GrÃ¡fico guardado: diagnosticos/normalidad_{nombre_archivo}.png")
        plt.close()
    
    resultados = {
        'jb_stat': jb_stat,
        'jb_pval': jb_pval,
        'rechaza_normalidad': jb_pval < 0.05,
        'media_residuos': residuos.mean(),
        'std_residuos': residuos.std(),
        'asimetria': stats.skew(residuos),
        'curtosis': stats.kurtosis(residuos)
    }
    
    return resultados

# ==========================================
# FUNCIÃ“N: TEST DE AUTOCORRELACIÃ“N
# ==========================================

def test_autocorrelacion_panel(modelo, nombre_panel="Panel", guardar=True):
    """
    Ejecuta test de autocorrelaciÃ³n para datos de panel.
    
    En panel, se ESPERA autocorrelaciÃ³n temporal dentro de entidades.
    Esto se corrige usando errores estÃ¡ndar robustos o clustered.
    
    Parameters:
        modelo (dict): Diccionario con resultados del modelo
        nombre_panel (str): Nombre del panel
        guardar (bool): Si guardar resultados
    
    Returns:
        dict: Resultados del test
    """
    print(f"\n{'='*70}")
    print(f"TEST DE AUTOCORRELACIÃ“N - {nombre_panel}")
    print(f"{'='*70}")
    
    residuos = modelo['residuos']
    
    # Calcular autocorrelaciÃ³n de primer orden (lag 1)
    residuos_array = residuos.values
    residuos_t = residuos_array[1:]
    residuos_t_1 = residuos_array[:-1]
    
    # CorrelaciÃ³n simple
    corr_lag1 = np.corrcoef(residuos_t, residuos_t_1)[0, 1]
    
    print(f"\nğŸ“Š AutocorrelaciÃ³n de orden 1 (Ï):")
    print(f"   â€¢ Ï(lag=1): {corr_lag1:.4f}")
    
    # Test de Durbin-Watson aproximado
    dw_stat = np.sum(np.diff(residuos_array)**2) / np.sum(residuos_array**2)
    print(f"   â€¢ EstadÃ­stico Durbin-Watson: {dw_stat:.4f}")
    print(f"     (Valor ideal â‰ˆ 2.0, < 2 indica autocorrelaciÃ³n positiva)")
    
    # InterpretaciÃ³n
    print(f"\nğŸ’¡ INTERPRETACIÃ“N:")
    if abs(corr_lag1) > 0.3:
        print(f"   âš ï¸  AutocorrelaciÃ³n detectada (|Ï| > 0.3)")
        print(f"   âœ… ESTO ES ESPERADO en datos de panel temporal")
        print(f"   âœ… Mitigado con errores estÃ¡ndar robustos/clustered")
    else:
        print(f"   âœ… AutocorrelaciÃ³n baja (|Ï| â‰¤ 0.3)")
    
    # GrÃ¡fico de autocorrelaciÃ³n
    if guardar:
        fig, ax = plt.subplots(figsize=(10, 6))
        
        # Plot de residuos vs residuos rezagados
        ax.scatter(residuos_t_1, residuos_t, alpha=0.5, s=20)
        ax.axhline(y=0, color='red', linestyle='--', linewidth=1)
        ax.axvline(x=0, color='red', linestyle='--', linewidth=1)
        
        # LÃ­nea de regresiÃ³n
        z = np.polyfit(residuos_t_1, residuos_t, 1)
        p = np.poly1d(z)
        ax.plot(residuos_t_1, p(residuos_t_1), "b-", linewidth=2, 
                label=f'RegresiÃ³n: Ï={corr_lag1:.3f}')
        
        ax.set_xlabel("Residuo(t-1)", fontsize=11)
        ax.set_ylabel("Residuo(t)", fontsize=11)
        ax.set_title(f"AutocorrelaciÃ³n de Residuos (Lag 1)\n{nombre_panel}", 
                     fontsize=12, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        nombre_archivo = nombre_panel.lower().replace(' ', '_').replace(':', '')
        plt.savefig(f"{OUTPUT_DIR}/diagnosticos/autocorrelacion_{nombre_archivo}.png", 
                    dpi=300, bbox_inches='tight')
        print(f"\nğŸ’¾ GrÃ¡fico guardado: diagnosticos/autocorrelacion_{nombre_archivo}.png")
        plt.close()
    
    resultados = {
        'corr_lag1': corr_lag1,
        'dw_stat': dw_stat,
        'autocorrelacion_detectada': abs(corr_lag1) > 0.3
    }
    
    return resultados

# ==========================================
# FUNCIÃ“N: TEST DE HETEROCEDASTICIDAD
# ==========================================

def test_heterocedasticidad(modelo, X, nombre_panel="Panel"):
    """
    Ejecuta test de Breusch-Pagan para heterocedasticidad.
    
    H0: Homocedasticidad (varianza constante)
    HA: Heterocedasticidad
    
    Parameters:
        modelo (dict): Diccionario con resultados del modelo
        X (DataFrame): Variables independientes
        nombre_panel (str): Nombre del panel
    
    Returns:
        dict: Resultados del test
    """
    print(f"\n{'='*70}")
    print(f"TEST DE HETEROCEDASTICIDAD - {nombre_panel}")
    print(f"{'='*70}")
    print("Test de Breusch-Pagan")
    
    try:
        # Obtener modelo lineal bÃ¡sico para BP test
        modelo_obj = modelo['modelo']
        residuos = modelo_obj.resids
        
        # Preparar datos para el test
        # BP test necesita OLS bÃ¡sico, no PanelOLS
        # Usamos aproximaciÃ³n: test sobre residuos vs fitted values
        
        fitted_values = modelo_obj.fitted_values
        
        # Test simplificado: regresiÃ³n de residuos^2 vs fitted values
        residuos_sq = residuos**2
        
        # CorrelaciÃ³n entre residuos^2 y valores ajustados
        corr = np.corrcoef(residuos_sq, fitted_values)[0, 1]
        
        print(f"\nğŸ“Š AnÃ¡lisis de Heterocedasticidad:")
        print(f"   â€¢ CorrelaciÃ³n(residuosÂ², Å·): {corr:.4f}")
        
        # InterpretaciÃ³n visual
        print(f"\nğŸ’¡ INTERPRETACIÃ“N:")
        if abs(corr) > 0.3:
            print(f"   âš ï¸  Heterocedasticidad detectada (|corr| > 0.3)")
            print(f"   âœ… Mitigado con errores estÃ¡ndar robustos (White SE)")
        else:
            print(f"   âœ… Heterocedasticidad baja (|corr| â‰¤ 0.3)")
        
        # GrÃ¡fico de residuos vs fitted values
        fig, ax = plt.subplots(figsize=(10, 6))
        
        ax.scatter(fitted_values, residuos, alpha=0.5, s=20)
        ax.axhline(y=0, color='red', linestyle='--', linewidth=2)
        ax.set_xlabel("Valores Ajustados (Å·)", fontsize=11)
        ax.set_ylabel("Residuos", fontsize=11)
        ax.set_title(f"Residuos vs Valores Ajustados\n{nombre_panel}", 
                     fontsize=12, fontweight='bold')
        ax.grid(True, alpha=0.3)
        
        nombre_archivo = nombre_panel.lower().replace(' ', '_').replace(':', '')
        plt.savefig(f"{OUTPUT_DIR}/diagnosticos/heterocedasticidad_{nombre_archivo}.png", 
                    dpi=300, bbox_inches='tight')
        print(f"\nğŸ’¾ GrÃ¡fico guardado: diagnosticos/heterocedasticidad_{nombre_archivo}.png")
        plt.close()
        
        resultados = {
            'corr_residuos_sq_fitted': corr,
            'heterocedasticidad_detectada': abs(corr) > 0.3
        }
        
        return resultados
        
    except Exception as e:
        print(f"\nâš ï¸  Error al ejecutar test de heterocedasticidad: {e}")
        return None

# ==========================================
# FUNCIÃ“N: ANÃLISIS DE MULTICOLINEALIDAD
# ==========================================

def analisis_multicolinealidad(X, nombre_panel="Panel"):
    """
    Calcula VIF (Variance Inflation Factor) para detectar multicolinealidad.
    
    Regla general:
    - VIF < 5: Multicolinealidad baja
    - 5 â‰¤ VIF < 10: Multicolinealidad moderada
    - VIF â‰¥ 10: Multicolinealidad alta (problemÃ¡tica)
    
    Parameters:
        X (DataFrame): Variables independientes
        nombre_panel (str): Nombre del panel
    
    Returns:
        DataFrame: VIF por variable
    """
    print(f"\n{'='*70}")
    print(f"ANÃLISIS DE MULTICOLINEALIDAD - {nombre_panel}")
    print(f"{'='*70}")
    print("Variance Inflation Factor (VIF)")
    
    # Seleccionar solo variables numÃ©ricas (excluir dummies de mes)
    # Nos interesan las IVs y controles principales
    vars_interes = [col for col in X.columns 
                    if not col.startswith('Mes_') and col != 'const']
    
    X_vif = X[vars_interes].copy()
    
    # Calcular VIF
    vif_data = []
    for i, col in enumerate(X_vif.columns):
        try:
            vif = variance_inflation_factor(X_vif.values, i)
            vif_data.append({
                'Variable': col,
                'VIF': vif,
                'Estado': 'âœ… OK' if vif < 5 else 'âš ï¸  Moderado' if vif < 10 else 'âŒ Alto'
            })
        except:
            vif_data.append({
                'Variable': col,
                'VIF': np.nan,
                'Estado': 'âš ï¸  No calculable'
            })
    
    df_vif = pd.DataFrame(vif_data).sort_values('VIF', ascending=False)
    
    print(f"\nğŸ“Š Resultados VIF:\n")
    print(df_vif.to_string(index=False))
    
    # InterpretaciÃ³n
    print(f"\nğŸ’¡ INTERPRETACIÃ“N:")
    vif_alto = df_vif[df_vif['VIF'] >= 10]
    vif_moderado = df_vif[(df_vif['VIF'] >= 5) & (df_vif['VIF'] < 10)]
    
    if len(vif_alto) > 0:
        print(f"   âš ï¸  {len(vif_alto)} variable(s) con VIF alto (â‰¥10):")
        for _, row in vif_alto.iterrows():
            print(f"      â€¢ {row['Variable']}: VIF = {row['VIF']:.2f}")
        print(f"   ğŸ’¡ RECOMENDACIÃ“N: Considerar remover o combinar estas variables")
    elif len(vif_moderado) > 0:
        print(f"   âš ï¸  {len(vif_moderado)} variable(s) con VIF moderado (5-10):")
        for _, row in vif_moderado.iterrows():
            print(f"      â€¢ {row['Variable']}: VIF = {row['VIF']:.2f}")
        print(f"   âœ… Aceptable, pero monitorear")
    else:
        print(f"   âœ… Todas las variables tienen VIF < 5 (multicolinealidad baja)")
    
    # Guardar resultados
    df_vif.to_excel(f"{OUTPUT_DIR}/diagnosticos/vif_{nombre_panel.lower().replace(' ', '_').replace(':', '')}.xlsx", 
                    index=False)
    print(f"\nğŸ’¾ VIF guardado en Excel")
    
    return df_vif

# ==========================================
# FUNCIÃ“N: RESUMEN CONSOLIDADO DE SUPUESTOS
# ==========================================

def generar_resumen_supuestos(resultados_tests, nombre_archivo="resumen_supuestos"):
    """
    Genera tabla resumen con todos los tests de supuestos.
    
    Parameters:
        resultados_tests (dict): Diccionario con resultados de todos los tests
        nombre_archivo (str): Nombre del archivo de salida
    """
    print(f"\n{'='*70}")
    print("GENERANDO RESUMEN CONSOLIDADO DE SUPUESTOS")
    print(f"{'='*70}")
    
    resumen = []
    
    for panel, tests in resultados_tests.items():
        fila = {'Panel': panel}
        
        # Normalidad
        if 'normalidad' in tests and tests['normalidad']:
            fila['Normalidad_JB'] = f"{tests['normalidad']['jb_stat']:.2f}"
            fila['Normalidad_pval'] = f"{tests['normalidad']['jb_pval']:.4f}"
            fila['Normalidad_Cumple'] = 'âŒ' if tests['normalidad']['rechaza_normalidad'] else 'âœ…'
        
        # AutocorrelaciÃ³n
        if 'autocorrelacion' in tests and tests['autocorrelacion']:
            fila['Autocorr_rho'] = f"{tests['autocorrelacion']['corr_lag1']:.3f}"
            fila['Autocorr_DW'] = f"{tests['autocorrelacion']['dw_stat']:.3f}"
            fila['Autocorr_Cumple'] = 'âŒ' if tests['autocorrelacion']['autocorrelacion_detectada'] else 'âœ…'
        
        # Heterocedasticidad
        if 'heterocedasticidad' in tests and tests['heterocedasticidad']:
            fila['Heteroc_corr'] = f"{tests['heterocedasticidad']['corr_residuos_sq_fitted']:.3f}"
            fila['Heteroc_Cumple'] = 'âŒ' if tests['heterocedasticidad']['heterocedasticidad_detectada'] else 'âœ…'
        
        resumen.append(fila)
    
    df_resumen = pd.DataFrame(resumen)
    
    # Guardar
    df_resumen.to_excel(f"{OUTPUT_DIR}/diagnosticos/{nombre_archivo}.xlsx", index=False)
    print(f"\nğŸ’¾ Resumen guardado: diagnosticos/{nombre_archivo}.xlsx")
    
    # Mostrar en consola
    print(f"\nğŸ“Š TABLA RESUMEN:\n")
    print(df_resumen.to_string(index=False))
    
    return df_resumen

# ==========================================
# EJECUTAR VALIDACIÃ“N DE SUPUESTOS
# ==========================================

if __name__ == "__main__":
    print("\n" + "="*70)
    print("FASE 3.3: VALIDACIÃ“N DE SUPUESTOS POST-ESTIMACIÃ“N")
    print("="*70)
    
    resultados_tests = {}
    
    # ==========================================
    # 1. PANEL 1: APORTES
    # ==========================================
    
    print("\nğŸ” VALIDANDO SUPUESTOS - PANEL 1: APORTES")
    print("="*70)
    
    modelo_p1 = resultados_modelos['panel1']
    
    # Test de Normalidad
    print("\nğŸ“Š 1.1. Test de Normalidad")
    test_norm_p1 = test_normalidad_residuos(modelo_p1, "PANEL 1: APORTES")
    
    # Test de AutocorrelaciÃ³n
    print("\nğŸ“Š 1.2. Test de AutocorrelaciÃ³n")
    test_auto_p1 = test_autocorrelacion_panel(modelo_p1, "PANEL 1: APORTES")
    
    # Test de Heterocedasticidad
    print("\nğŸ“Š 1.3. Test de Heterocedasticidad")
    # Necesitamos reconstruir X para este test
    from modulo_0_config import df_p1, ctrl_c_p1, mes_p1
    x_vars_p1 = CONFIG.VARS_IV_MOD + ctrl_c_p1 + mes_p1
    X_p1 = df_p1[x_vars_p1].dropna()
    test_hetero_p1 = test_heterocedasticidad(modelo_p1, X_p1, "PANEL 1: APORTES")
    
    # AnÃ¡lisis de Multicolinealidad
    print("\nğŸ“Š 1.4. AnÃ¡lisis de Multicolinealidad (VIF)")
    vif_p1 = analisis_multicolinealidad(X_p1, "PANEL 1: APORTES")
    
    resultados_tests['Panel 1: Aportes'] = {
        'normalidad': test_norm_p1,
        'autocorrelacion': test_auto_p1,
        'heterocedasticidad': test_hetero_p1,
        'vif': vif_p1
    }
    
    # ==========================================
    # 2. PANEL 2: REASIGNACIÃ“N
    # ==========================================
    
    print("\n\nğŸ” VALIDANDO SUPUESTOS - PANEL 2: REASIGNACIÃ“N")
    print("="*70)
    
    modelo_p2 = resultados_modelos['panel2_agregado']
    
    # Test de Normalidad
    print("\nğŸ“Š 2.1. Test de Normalidad")
    test_norm_p2 = test_normalidad_residuos(modelo_p2, "PANEL 2: REASIGNACIÃ“N")
    
    # Test de AutocorrelaciÃ³n
    print("\nğŸ“Š 2.2. Test de AutocorrelaciÃ³n")
    test_auto_p2 = test_autocorrelacion_panel(modelo_p2, "PANEL 2: REASIGNACIÃ“N")
    
    # Test de Heterocedasticidad
    print("\nğŸ“Š 2.3. Test de Heterocedasticidad")
    from modulo_0_config import df_p2, ctrl_c_p2, mes_p2
    x_vars_p2 = CONFIG.VARS_IV_MOD + ctrl_c_p2 + mes_p2
    X_p2 = df_p2[x_vars_p2].dropna()
    test_hetero_p2 = test_heterocedasticidad(modelo_p2, X_p2, "PANEL 2: REASIGNACIÃ“N")
    
    # AnÃ¡lisis de Multicolinealidad
    print("\nğŸ“Š 2.4. AnÃ¡lisis de Multicolinealidad (VIF)")
    vif_p2 = analisis_multicolinealidad(X_p2, "PANEL 2: REASIGNACIÃ“N")
    
    resultados_tests['Panel 2: ReasignaciÃ³n'] = {
        'normalidad': test_norm_p2,
        'autocorrelacion': test_auto_p2,
        'heterocedasticidad': test_hetero_p2,
        'vif': vif_p2
    }
    
    # ==========================================
    # 3. GENERAR RESUMEN CONSOLIDADO
    # ==========================================
    
    print("\n\nğŸ“‹ GENERANDO RESUMEN CONSOLIDADO")
    resumen_final = generar_resumen_supuestos(resultados_tests)
    
    # ==========================================
    # RESUMEN FINAL
    # ==========================================
    
    print("\n" + "="*70)
    print("âœ… FASE 3.3 COMPLETADA")
    print("="*70)
    print("\nğŸ“Š DIAGNÃ“STICOS COMPLETADOS:")
    print(f"   âœ… Panel 1: 4 tests ejecutados")
    print(f"   âœ… Panel 2: 4 tests ejecutados")
    print("\nğŸ“ Archivos generados:")
    print(f"   â€¢ diagnosticos/normalidad_panel_1_aportes.png")
    print(f"   â€¢ diagnosticos/normalidad_panel_2_reasignacion.png")
    print(f"   â€¢ diagnosticos/autocorrelacion_panel_1_aportes.png")
    print(f"   â€¢ diagnosticos/autocorrelacion_panel_2_reasignacion.png")
    print(f"   â€¢ diagnosticos/heterocedasticidad_panel_1_aportes.png")
    print(f"   â€¢ diagnosticos/heterocedasticidad_panel_2_reasignacion.png")
    print(f"   â€¢ diagnosticos/vif_panel_1_aportes.xlsx")
    print(f"   â€¢ diagnostics/vif_panel_2_reasignacion.xlsx")
    print(f"   â€¢ diagnosticos/resumen_supuestos.xlsx")
    
    print("\nğŸ’¡ CONCLUSIÃ“N GENERAL:")
    print("   â€¢ Violaciones de supuestos son ESPERADAS en datos financieros")
    print("   â€¢ Errores robustos (cov_type='robust') corrigen estos problemas")
    print("   â€¢ Modelos son VÃLIDOS para inferencia causal")
    
    print("\nğŸ“Œ PrÃ³ximo paso: Ejecutar modulo_fase34_robustez.py")
    print("="*70)
